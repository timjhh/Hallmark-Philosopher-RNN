{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import requests as rq\n",
    "import sys\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"nietzsche.txt\", encoding=\"utf-8\")\n",
    "text_niet = file.read()\n",
    "# 732020:732176\n",
    "\n",
    "file_date = open(\"baddate.txt\", encoding=\"utf-8\")\n",
    "text_date = file_date.read()\n",
    "\n",
    "EPOCHS = 10\n",
    "diversity = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "niet = text_niet.split(\"\\n\")\n",
    "date = text_date.split(\"\\n\")\n",
    "text = []\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "counter = 0\n",
    "while i < len(niet) and j < len(date):\n",
    "    if counter % 2 == 0:\n",
    "        text.append(niet[i])\n",
    "        i += 1\n",
    "    else:\n",
    "        text.append(date[j])\n",
    "        j += 1\n",
    "    counter += 1\n",
    "\n",
    "# text = text + niet[i:len(niet)]\n",
    "# text = text + date[j:len(date)]\n",
    "\n",
    "sep = \"\\n\"\n",
    "text = sep.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timjh\\AppData\\Local\\Temp\\ipykernel_48580\\315039847.py:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\timjh\\AppData\\Local\\Temp\\ipykernel_48580\\315039847.py:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/58 [============================>.] - ETA: 0s - loss: 3.1732 - categorical_crossentropy: 3.1732 - accuracy: 0.1914\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"hat *\n",
      "106.\n",
      "bad, is he? *\n",
      "\n",
      "LEIGH\n",
      "How is i\"\n",
      "hat *\n",
      "106.\n",
      "bad, is he? *\n",
      "\n",
      "LEIGH\n",
      "How is ing the the the the the the the the thet and there the thes the the the the the the theng the the the the the the the theng the the the the the the the thesthe the the there the the theng the thengete the theng and tout and the the the the the the the the the thent and the the the the the the there the the the the the the the the the theng the the the the the there the the thent ang the the the the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"hat *\n",
      "106.\n",
      "bad, is he? *\n",
      "\n",
      "LEIGH\n",
      "How is i\"\n",
      "hat *\n",
      "106.\n",
      "bad, is he? *\n",
      "\n",
      "LEIGH\n",
      "How is itt tod tort ton thents cof wof  ontongon and thantithateent west terent the pand ane the wits contead and pes thered wite thes, thendithestite the the me thertas thest wore t tot till theog wit the ther of thendithelondat on tores and tore to of su fas re toon t ong ing and potis this ind tont is ons pn theme pite co thang thetheitheres of tos angouls theng thes angcareut ing ton be ther the se on\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"hat *\n",
      "106.\n",
      "bad, is he? *\n",
      "\n",
      "LEIGH\n",
      "How is i\"\n",
      "hat *\n",
      "106.\n",
      "bad, is he? *\n",
      "\n",
      "LEIGH\n",
      "How is int.cind aong tamre oualit yhin ,omachinrs *ttanptince roavennebm tveveceste *stede,te fesitaslnt itr thes mabe theongoas ofeckd thasd\n",
      "in withe kudt etliintitos W\n",
      " sake: ne r. thico nwica wise _nhy wet sodolcasd  mes, awdereg\n",
      "of ne (e.\n",
      "_tount themthondiont sithet tritetgeitoty tonnstiufetintes at theeresttDout cyk y3G.\n",
      "fant angis entap oflt ontaure enta ttarangisetythous it than_ of 7ncoutt ta mefn\n",
      "58/58 [==============================] - 103s 2s/step - loss: 3.1707 - categorical_crossentropy: 3.1707 - accuracy: 0.1918\n",
      "Epoch 2/10\n",
      "57/58 [============================>.] - ETA: 0s - loss: 2.4795 - categorical_crossentropy: 2.4795 - accuracy: 0.3132\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"rs Post.\n",
      "41.\n",
      "39 39 INT. CONNER AND BRAD’\"\n",
      "rs Post.\n",
      "41.\n",
      "39 39 INT. CONNER AND BRAD’S ANT ON\n",
      "ERIN\n",
      "\n",
      "LEIGH\n",
      "\n",
      "LEIGH\n",
      "\n",
      "(03/28/16) 16) *\n",
      "\n",
      "LEIGH\n",
      "\n",
      "\n",
      "LEIGH\n",
      "\n",
      "\n",
      "Leigh of all of the will the prou the whe pous of the wall the bue the wore wor the wore and of the in the proul the in the wion the mor the wore will in the wore wor a dous of the prouch in the wore in the  of the wall of the soun the which a doul the be whe wion the which and the in the the which to and the _ of the which in the woul\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rs Post.\n",
      "41.\n",
      "39 39 INT. CONNER AND BRAD’\"\n",
      "rs Post.\n",
      "41.\n",
      "39 39 INT. CONNER AND BRAD’S CONNER\n",
      "\n",
      "(som all bus wion in the in s in the \"reous pouce which wor ald war be the she thin the mor wore _tou the sound of of not all wion of of col blich s of the bect of of ou sou of go all souro of at our of be wor cous and able poll bee se wing se for ere cunct of at which the which to the wore poul wiou s of all or the ar are in the whan it a loull a coull of whe  of hio lith to be to bed p\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"rs Post.\n",
      "41.\n",
      "39 39 INT. CONNER AND BRAD’\"\n",
      "rs Post.\n",
      "41.\n",
      "39 39 INT. CONNER AND BRAD’s ihas ould wurt _rey (a wict hims nom; couss:\n",
      "\n",
      "wo chi’n styounc uw\n",
      "\n",
      "sur ably *\n",
      "\n",
      "Leaouny say noe the? Hut' heron.\n",
      "al tha  e blt ant and no pouririty nol mhif s of denc.\n",
      "s opprt us whim net wiok aun gine fug\n",
      "P0e \"now chis the moo\n",
      "liou fiare ofe?\n",
      "(32.\n",
      "\n",
      "nous to und -omy\n",
      "31e.\n",
      "(03/rAn\n",
      "_y wepkeut of romere of blit *\n",
      "\"ire wer thege Leiel shis. wongl sx- phen thgh I woik lo- den inhe, in Pon curill,. just\n",
      "58/58 [==============================] - 105s 2s/step - loss: 2.4789 - categorical_crossentropy: 2.4789 - accuracy: 0.3133\n",
      "Epoch 3/10\n",
      "57/58 [============================>.] - ETA: 0s - loss: 2.1948 - categorical_crossentropy: 2.1948 - accuracy: 0.3773\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"the extent of\n",
      "worth the effort.\n",
      "mistakin\"\n",
      "the extent of\n",
      "worth the effort.\n",
      "mistaking the prong the somen the prong the pround and the prong the mong the prong the poring the proming of the mand and the prong the prong the prong the some on the for the prone and and the prong the proper of the prong the prong the what the proper and the wath who bean the prean the prong the pround and the prong the prong the proring the proun the prout the _sound and the pround and the prong the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"the extent of\n",
      "worth the effort.\n",
      "mistakin\"\n",
      "the extent of\n",
      "worth the effort.\n",
      "mistaking and ding the prond the shar and and the somen the _and a doment of the rean\n",
      "groping in the stong the _sean the prat And and and the wach as ens and and exper com and but of the pround and and in the who her the propts not poned the mund the mong the  of the _ of the mosh and the pron the comprent of the grour and bent of the gont of hive and on the mong wher \"bean of the but the wack of a lad \"h\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"the extent of\n",
      "worth the effort.\n",
      "mistakin\"\n",
      "the extent of\n",
      "worth the effort.\n",
      "mistaking whir siver.\n",
      "I’d expad hau the notacexp. ERIN’M OONER\n",
      "ERIE ALLESON\n",
      "\n",
      "MILO\n",
      "evfice, dowing hammery of 17Bmen’s and moru ower emal my. thourpual uf\n",
      "Ar8 prirm bestcon this,\n",
      "Brud ard but toands ean whut es, ef exe mond\n",
      "billd nocendsp of for of the elion the fich and) beand hed Thanger. *\n",
      "kenct of fanhd gimpining,\n",
      "as\n",
      "She MICON\n",
      "Hetrostint man thea agm it\n",
      "ghin whif the are _mos  that. Hes, when doros bat \n",
      "58/58 [==============================] - 102s 2s/step - loss: 2.1943 - categorical_crossentropy: 2.1943 - accuracy: 0.3775\n",
      "Epoch 4/10\n",
      "57/58 [============================>.] - ETA: 0s - loss: 2.0185 - categorical_crossentropy: 2.0185 - accuracy: 0.4225\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"es, and hates.\n",
      "That whole “I’m prepared \"\n",
      "es, and hates.\n",
      "That whole “I’m prepared to the parter to to the _that was to to the wast to the dother to the same to to the becomand to the somenter and to that to to that to to the going to the somenter to the readen to to the storner to the somenting to thing to to the sater and to the somenting to the somenting to the starter to the somenter to to the proters to the realing to the same to the somenter to the pasting to the wasting t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"es, and hates.\n",
      "That whole “I’m prepared \"\n",
      "es, and hates.\n",
      "That whole “I’m prepared beat doon the mate and tok is that this take that to\n",
      "Brad toker to to to to simen a comestard and that that was being that to the seating the realing to some to to that this stalle the of the moen ald as it to the bat to that is to this wath to the wast and that to treat and have wast that that and to to saboursting to the goisting to to to the dedentander of the raal to had that this is the preat\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"es, and hates.\n",
      "That whole “I’m prepared \"\n",
      "es, and hates.\n",
      "That whole “I’m prepared _out\n",
      "M.IN\n",
      "\n",
      "38 so. *\n",
      "\n",
      "I’m not fill and ?\n",
      "Blad Rive have have wored are is itristhop Dot _didden is\n",
      "Oocumanter reatratart thoponegrtanchillsilisecter of his takan stor in tho it wordarimattayitoding datessaiknowing that muhurhal and _way the defolion.\n",
      "whith dedation food.\n",
      "Godiblepeptereity pealorer\n",
      "continteld to \n",
      "aner and reveraning\n",
      "suppatabuepser and antel is take ais biokely.\n",
      "2) The p)ornourdeanth\n",
      "58/58 [==============================] - 98s 2s/step - loss: 2.0178 - categorical_crossentropy: 2.0178 - accuracy: 0.4227\n",
      "Epoch 5/10\n",
      "57/58 [============================>.] - ETA: 0s - loss: 1.8951 - categorical_crossentropy: 1.8951 - accuracy: 0.4550\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" to back-worlds and false godheads are\n",
      "B\"\n",
      " to back-worlds and false godheads are\n",
      "BRAD\n",
      "destent of the most the most the pression of the sessed the most the prist of the most the restion of the most the pression of the prist is a some and the prises of the most and the most of the result of the of the pression of the most the pressous of the pression of the proses of the pression of the most is a proses and and the restion of the pression of the sessent of the proses of the sesse\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" to back-worlds and false godheads are\n",
      "B\"\n",
      " to back-worlds and false godheads are\n",
      "Blue Rev. (03/28/16) 61.\n",
      "\n",
      "ALLISON\n",
      "*\n",
      "for the rester of the forms of the to gon of the resorn"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "seqlen = 40\n",
    "step = seqlen\n",
    "sentences = []\n",
    "for i in range(0, len(text) - seqlen - 1, step):\n",
    "    sentences.append(text[i: i + seqlen + 1])\n",
    "\n",
    "x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "    preds = preds / np.sum(preds)                #\n",
    "    probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "    return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "    \n",
    "    for diversity in [0.2, 0.5, 1.0]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + seqlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            next_index = sample(preds[0, -1], diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          callbacks=[print_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
