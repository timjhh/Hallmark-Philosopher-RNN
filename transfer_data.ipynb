{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import requests as rq\n",
    "import sys\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"nietzsche.txt\", encoding=\"utf-8\")\n",
    "text_niet = file.read()\n",
    "# 732020:732176\n",
    "\n",
    "file_date = open(\"baddate.txt\", encoding=\"utf-8\")\n",
    "text_date = file_date.read()\n",
    "\n",
    "EPOCHS = 10\n",
    "diversity = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "niet = text_niet.split(\"\\n\")\n",
    "date = text_date.split(\"\\n\")\n",
    "text = []\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "counter = 0\n",
    "while i < len(niet) and j < len(date):\n",
    "    if counter % 2 == 0:\n",
    "        text.append(niet[i])\n",
    "        i += 1\n",
    "    else:\n",
    "        text.append(date[j])\n",
    "        j += 1\n",
    "    counter += 1\n",
    "\n",
    "# text = text + niet[i:len(niet)]\n",
    "# text = text + date[j:len(date)]\n",
    "\n",
    "sep = \"\\n\"\n",
    "text = sep.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timjh\\AppData\\Local\\Temp\\ipykernel_8524\\1519832955.py:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\timjh\\AppData\\Local\\Temp\\ipykernel_8524\\1519832955.py:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "57/58 [============================>.] - ETA: 0s - loss: 3.1904 - categorical_crossentropy: 3.1904 - accuracy: 0.1863\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"n the *\n",
      "isolation from men and things th\"\n",
      "58/58 [==============================] - 30s 488ms/step - loss: 3.1890 - categorical_crossentropy: 3.1890 - accuracy: 0.1865\n",
      "Epoch 2/20\n",
      "57/58 [============================>.] - ETA: 0s - loss: 2.4657 - categorical_crossentropy: 2.4657 - accuracy: 0.3158\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e.)\n",
      "Sure.\n",
      "\n",
      "LEIGH\n",
      "\n",
      "Then why aren’t you gi\"\n",
      "58/58 [==============================] - 25s 442ms/step - loss: 2.4652 - categorical_crossentropy: 2.4652 - accuracy: 0.3159\n",
      "Epoch 3/20\n",
      "57/58 [============================>.] - ETA: 0s - loss: 2.1753 - categorical_crossentropy: 2.1753 - accuracy: 0.3820\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"can find in antiquity, viz.:--\n",
      "ALLISON\n",
      "\n",
      "\"\n",
      "58/58 [==============================] - 28s 489ms/step - loss: 2.1749 - categorical_crossentropy: 2.1749 - accuracy: 0.3822\n",
      "Epoch 4/20\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.0061 - categorical_crossentropy: 2.0061 - accuracy: 0.4257\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" the _strongest_\n",
      "CONNER\n",
      "power: the other\"\n",
      "58/58 [==============================] - 34s 596ms/step - loss: 2.0061 - categorical_crossentropy: 2.0061 - accuracy: 0.4257\n",
      "Epoch 5/20\n",
      "57/58 [============================>.] - ETA: 0s - loss: 1.8879 - categorical_crossentropy: 1.8879 - accuracy: 0.4561\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" The success of determinism, the genealo\"\n",
      "58/58 [==============================] - 29s 507ms/step - loss: 1.8880 - categorical_crossentropy: 1.8880 - accuracy: 0.4560\n",
      "Epoch 6/20\n",
      "57/58 [============================>.] - ETA: 0s - loss: 1.7970 - categorical_crossentropy: 1.7970 - accuracy: 0.4820\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" sorry. I didn’t mean it that\n",
      "\n",
      "way. I’m \"\n",
      "58/58 [==============================] - 29s 503ms/step - loss: 1.7970 - categorical_crossentropy: 1.7970 - accuracy: 0.4820\n",
      "Epoch 7/20\n",
      "57/58 [============================>.] - ETA: 0s - loss: 1.7255 - categorical_crossentropy: 1.7255 - accuracy: 0.5014\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ties:\n",
      "I’m not very happy with you either\"\n",
      "58/58 [==============================] - 29s 498ms/step - loss: 1.7254 - categorical_crossentropy: 1.7254 - accuracy: 0.5015\n",
      "Epoch 8/20\n",
      "57/58 [============================>.] - ETA: 0s - loss: 1.6704 - categorical_crossentropy: 1.6704 - accuracy: 0.5161\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ning_ life.\n",
      "MILO\n",
      "\n",
      "Okay. So what did you \"\n",
      "58/58 [==============================] - 29s 501ms/step - loss: 1.6703 - categorical_crossentropy: 1.6703 - accuracy: 0.5161\n",
      "Epoch 9/20\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6239 - categorical_crossentropy: 1.6239 - accuracy: 0.5282\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"value of all _strong_ belief. Christiani\"\n",
      "58/58 [==============================] - 34s 598ms/step - loss: 1.6239 - categorical_crossentropy: 1.6239 - accuracy: 0.5282\n",
      "Epoch 10/20\n",
      "57/58 [============================>.] - ETA: 0s - loss: 1.5865 - categorical_crossentropy: 1.5865 - accuracy: 0.5372\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"to face with an actual school for the te\"\n",
      "58/58 [==============================] - 30s 518ms/step - loss: 1.5866 - categorical_crossentropy: 1.5866 - accuracy: 0.5372\n",
      "Epoch 11/20\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5563 - categorical_crossentropy: 1.5563 - accuracy: 0.5450\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"u want to be when you\n",
      "127.\n",
      "grew up?\n",
      "\n",
      "LEI\"\n",
      "58/58 [==============================] - 28s 497ms/step - loss: 1.5563 - categorical_crossentropy: 1.5563 - accuracy: 0.5450\n",
      "Epoch 12/20\n",
      "57/58 [============================>.] - ETA: 0s - loss: 1.5296 - categorical_crossentropy: 1.5296 - accuracy: 0.5521\n",
      "----- Generating text after Epoch: 11\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"punishment and conceived as an error; er\"\n",
      "58/58 [==============================] - 29s 506ms/step - loss: 1.5293 - categorical_crossentropy: 1.5293 - accuracy: 0.5521\n",
      "Epoch 13/20\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5066 - categorical_crossentropy: 1.5066 - accuracy: 0.5586\n",
      "----- Generating text after Epoch: 12\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ose who are _morally obsessed_ and _anti\"\n",
      "58/58 [==============================] - 37s 650ms/step - loss: 1.5066 - categorical_crossentropy: 1.5066 - accuracy: 0.5586\n",
      "Epoch 14/20\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4850 - categorical_crossentropy: 1.4850 - accuracy: 0.5630\n",
      "----- Generating text after Epoch: 13\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ich it therefore necessarily\n",
      "Stop callin\"\n",
      "58/58 [==============================] - 35s 608ms/step - loss: 1.4850 - categorical_crossentropy: 1.4850 - accuracy: 0.5630\n",
      "Epoch 15/20\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4684 - categorical_crossentropy: 1.4684 - accuracy: 0.5673\n",
      "----- Generating text after Epoch: 14\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"s regarded as art\n",
      "A pause and then “ding\"\n",
      "58/58 [==============================] - 30s 522ms/step - loss: 1.4684 - categorical_crossentropy: 1.4684 - accuracy: 0.5673\n",
      "Epoch 16/20\n",
      "57/58 [============================>.] - ETA: 0s - loss: 1.4524 - categorical_crossentropy: 1.4524 - accuracy: 0.5723\n",
      "----- Generating text after Epoch: 15\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"that so he could write this hit\n",
      "chronolo\"\n",
      "58/58 [==============================] - 30s 530ms/step - loss: 1.4523 - categorical_crossentropy: 1.4523 - accuracy: 0.5724\n",
      "Epoch 17/20\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4364 - categorical_crossentropy: 1.4364 - accuracy: 0.5760\n",
      "----- Generating text after Epoch: 16\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"em worth while to me. Still, Socialism,\n",
      "\"\n",
      "58/58 [==============================] - 39s 685ms/step - loss: 1.4364 - categorical_crossentropy: 1.4364 - accuracy: 0.5760\n",
      "Epoch 18/20\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4241 - categorical_crossentropy: 1.4241 - accuracy: 0.5788\n",
      "----- Generating text after Epoch: 17\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"unity to stab me in the back,\n",
      "nonsense o\"\n",
      "58/58 [==============================] - 35s 605ms/step - loss: 1.4241 - categorical_crossentropy: 1.4241 - accuracy: 0.5788\n",
      "Epoch 19/20\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4122 - categorical_crossentropy: 1.4122 - accuracy: 0.5818\n",
      "----- Generating text after Epoch: 18\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"f bitterness,--in short, we Germans _wil\"\n",
      "58/58 [==============================] - 32s 554ms/step - loss: 1.4122 - categorical_crossentropy: 1.4122 - accuracy: 0.5818\n",
      "Epoch 20/20\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4016 - categorical_crossentropy: 1.4016 - accuracy: 0.5850\n",
      "----- Generating text after Epoch: 19\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"S REVIEW OFFICES - DAY\n",
      "even to itself, w\"\n",
      "58/58 [==============================] - 33s 568ms/step - loss: 1.4016 - categorical_crossentropy: 1.4016 - accuracy: 0.5850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e36e77a980>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "seqlen = 40\n",
    "step = seqlen\n",
    "sentences = []\n",
    "for i in range(0, len(text) - seqlen - 1, step):\n",
    "    sentences.append(text[i: i + seqlen + 1])\n",
    "\n",
    "x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "    preds = preds / np.sum(preds)                #\n",
    "    probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "    return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "    \n",
    "    #for diversity in [0.2, 0.5, 1.0]:\n",
    "    diversity = 0.5\n",
    "    print('----- diversity:', diversity)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + seqlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    #sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "    \n",
    "        preds = model.predict(x_pred, verbose=0)\n",
    "        next_index = sample(preds[0, -1], diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "            #sys.stdout.write(next_char)\n",
    "        #print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Generating with seed: \"helter-skelter, like a torrent that will\"\n",
      "helter-skelter, like a torrent that will\n",
      "(beat). The digned to be i"
     ]
    }
   ],
   "source": [
    "seqlenn = 40\n",
    "\n",
    "def generate_date(seed):\n",
    "    output = \"\"\n",
    "    print()\n",
    "    rand_evn = random.randint(0,100)\n",
    "\n",
    "    sentence = seed\n",
    "    generated = ''\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, seqlenn, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "        preds = model.predict(x_pred, verbose=0)\n",
    "        next_index = sample(preds[0, -1], 0.7)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "        output = output + next_char\n",
    "        sys.stdout.write(next_char)\n",
    "    return output\n",
    "\n",
    "\n",
    "output = \"\"\n",
    "print()\n",
    "\n",
    "sentence = text[1018:1058]\n",
    "generated = ''\n",
    "\n",
    "generated += sentence\n",
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "sys.stdout.write(generated)\n",
    "\n",
    "for i in range(600):\n",
    "    x_pred = np.zeros((1, seqlenn, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "    \n",
    "    preds = model.predict(x_pred, verbose=0)\n",
    "    next_index = sample(preds[0, -1], 0.7)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    sentence = sentence[1:] + next_char\n",
    "    output = output + next_char\n",
    "    sys.stdout.write(next_char)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helter-skelter, like a torrent that will and lathers, Ind's should be not be attell he personalion and play and demsinally\n",
    "CONNER\n",
    "omating eternal stop it. *\n",
    "\n",
    "LEIGH *\n",
    "The German,_ conquent relar alogation\n",
    "(LEIggg)\n",
    "\n",
    "CONNER\n",
    "is a sign of the procuse of the world appears of self he had us. *\n",
    "\n",
    "CONNER\n",
    "The Pessimism is not political property and a comenning. *\n",
    "belief in the forcow. In propers of the word to show by music who presents.\n",
    "\n",
    "ERIN\n",
    "130\n",
    "\n",
    "\n",
    "helter-skelter, like a torrent that will, no prevent and date things the rons of \"one of allight to who world of the Nihilism, which see parting, indonest of the oppressed the strougely developing your name and interpreted of preventingly abade\n",
    "Can Christian and not those relations subriniin convilling the _trarterstangencally\" has been about in one barbare up would show in the prover of the downfuse or him preeding). What does not\n",
    "I th\n",
    "\n",
    "\n",
    "this of _humanity_ and life, but whose oright and\n",
    "On the wearthomed\n",
    "What you don’t know’s dogmants and from the table the religious first second to paper who\n",
    "ALLISON\n",
    "animal _from the\n",
    "Holy spirityed _absence_ for the everything?\n",
    "animal fild happeners as the flacking intellectuar revolly mean hersto not it is the menss from be same into _trence there socies._\n",
    "Thank you...\n",
    "resplitering the time who would leave, who a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
