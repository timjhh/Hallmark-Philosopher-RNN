{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import requests as rq\n",
    "import sys\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"nietzsche.txt\", encoding=\"utf-8\")\n",
    "text_niet = file.read()\n",
    "# 732020:732176\n",
    "\n",
    "file_date = open(\"baddate.txt\", encoding=\"utf-8\")\n",
    "text_date = file.read()\n",
    "\n",
    "EPOCHS = 10\n",
    "diversity = 0.5\n",
    "\n",
    "# Do we not\n",
    "# hear the noise of the grave-diggers who are burying God? Do we not smell\n",
    "# the divine putrefaction?â€”for even Gods putrefy! God is dead! God remains\n",
    "# dead! And we have killed him!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)\n",
    "    preds = preds / np.sum(preds)               \n",
    "    probas = np.random.multinomial(1, preds, 1) \n",
    "    return np.argmax(probas)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text_niet)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "seqlen = 40\n",
    "step = seqlen\n",
    "sentences = []\n",
    "for i in range(40, len(text_niet) - seqlen - 1, step):\n",
    "    sentences.append(text_niet[i: i + seqlen + 1])\n",
    "\n",
    "x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "        \n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model1.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model1.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "def on_epoch_end_niet(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text_niet) - seqlen - 1)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text_niet[start_index: start_index + seqlen]\n",
    "    generated += sentence\n",
    "    #print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    #sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "        preds = model1.predict(x_pred, verbose=0)\n",
    "        next_index = sample(preds[0, -1], diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        #sys.stdout.write(next_char) \n",
    "\n",
    "    # for diversity in [0.2, 0.5, 1.0]:\n",
    "    #     #print('----- diversity:', diversity)\n",
    "\n",
    "    #     generated = ''\n",
    "    #     sentence = text_niet[start_index: start_index + seqlen]\n",
    "    #     generated += sentence\n",
    "    #     #print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    #     #sys.stdout.write(generated)\n",
    "\n",
    "    #     for i in range(400):\n",
    "    #         x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "    #         for t, char in enumerate(sentence):\n",
    "    #             x_pred[0, t, char_indices[char]] = 1.\n",
    "            \n",
    "    #         preds = model1.predict(x_pred, verbose=0)\n",
    "    #         next_index = sample(preds[0, -1], diversity)\n",
    "    #         next_char = indices_char[next_index]\n",
    "\n",
    "    #         sentence = sentence[1:] + next_char\n",
    "\n",
    "    #         #sys.stdout.write(next_char)   \n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end_niet)\n",
    "\n",
    "\n",
    "model1.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=EPOCHS,\n",
    "          callbacks=[print_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text_date)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "seqlen = 40\n",
    "step = seqlen\n",
    "sentences = []\n",
    "for i in range(40, len(text_date) - seqlen - 1, step):\n",
    "    sentences.append(text_date[i: i + seqlen + 1])\n",
    "\n",
    "x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model2.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "def on_epoch_end_date(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text_niet) - seqlen - 1)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text_date[start_index: start_index + seqlen]\n",
    "    generated += sentence\n",
    "    #print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    #sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "        preds = model2.predict(x_pred, verbose=0)\n",
    "        next_index = sample(preds[0, -1], diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end_date)\n",
    "\n",
    "model2.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=EPOCHS,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat1 = Flatten()(model1.layers[-1].output)\n",
    "flat2 = Flatten()(model2.layers[-1].output)\n",
    "output = LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True)\n",
    "\n",
    "model3 = keras.Model(inputs=[model1.inputs,model2.inputs], outputs=output)\n",
    "\n",
    "for i in range(len(model3.layers)-1):\n",
    "    layer = model3.layers[i]\n",
    "    layer.trainable = False\n",
    "\n",
    "model3.add(Dense(len(chars), activation='softmax')([flat1,flat2]))\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    rand_evn = random.randint(0,100)\n",
    "\n",
    "    generated = ''\n",
    "    if rand_evn % 2 == 0:\n",
    "        start_index = random.randint(0, len(text_date) - seqlen - 1)\n",
    "        sentence = text_date[start_index: start_index + seqlen]\n",
    "    else:\n",
    "        start_index = random.randint(0, len(text_niet) - seqlen - 1)\n",
    "        sentence = text_niet[start_index: start_index + seqlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "        preds = model3.predict(x_pred, verbose=0)\n",
    "        next_index = sample(preds[0, -1], 0.5)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    " \n",
    "model3.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=EPOCHS,\n",
    "          callbacks=[print_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
