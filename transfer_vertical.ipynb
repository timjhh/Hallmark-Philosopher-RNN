{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import requests as rq\n",
    "import sys\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 EXT. PORTLAND - NIGHT\n",
      "Establishing shot of Portland, Oregon. *\n",
      "2 2 EXT. RICHARDS REVIEW OFFICES - NIGHT\n",
      "Establishing shot of the offices of the Richardson Review,\n",
      "located in an old warehouse turned into modern office space.\n",
      "3 3 INT. ALLISON’S OFFICE - NIGHT *\n",
      "The office of the head of the Richar\n"
     ]
    }
   ],
   "source": [
    "file = open(\"baddate.txt\", encoding=\"utf-8\")\n",
    "text = file.read()\n",
    "\n",
    "print(text[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open(\"nietzsche.txt\", encoding=\"utf-8\")\n",
    "text2 = file2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syosh\\AppData\\Local\\Temp\\ipykernel_23696\\144191774.py:13: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\syosh\\AppData\\Local\\Temp\\ipykernel_23696\\144191774.py:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 3.7117 - categorical_crossentropy: 3.7117 - accuracy: 0.1351\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" it happen however it’s\n",
      "going to happen.\"\n",
      " it happen however it’s\n",
      "going to happen.   ne s   f t  taeN d \n",
      "  ef t   t \n",
      "  e g t  tt t le \n",
      "m b\n",
      " er  te a ase s A nrdd a e  e  ges ee   \n",
      "a \n",
      "e t ese an e\n",
      "     \n",
      "aa te tn  anep eis   ah sen i d e  t\n",
      "e s  e\n",
      "oe i n eee e  a  e n ll    eR n  a   e    raeter ee o oa se  Iee gee o    ioe     a e in ot a  e \n",
      "Hee  the \n",
      "  d e   TaaTse e ee i s \n",
      "n te ha e t nr aor  \n",
      "l aa heioe teo   ae ice  aa  o\n",
      "21/21 [==============================] - 98s 5s/step - loss: 3.7117 - categorical_crossentropy: 3.7117 - accuracy: 0.1351\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 3.2721 - categorical_crossentropy: 3.2721 - accuracy: 0.1770\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" to Conner and Leigh on the date.\n",
      "CONNER\"\n",
      " to Conner and Leigh on the date.\n",
      "CONNERe N o  t l l to t o no  he e he t re s t Ne rel ce  Ne I  t L  ot Con  t  I wh tet io  t t to t s fith t te n s  E  t fe se oin g t ee fo yor  le re re INNINNF \n",
      "NNNE Br  e lo t   L I te  u tn Non NN t n. aa  ti  s me afr t an aatl ng te t me d Nt o  wet te n le d a ato  t u s y re het a linl aH ne t t  o s  t t lhe t s at nco ore de e io tn eo  ha \n",
      "21/21 [==============================] - 93s 4s/step - loss: 3.2721 - categorical_crossentropy: 3.2721 - accuracy: 0.1770\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.8180 - categorical_crossentropy: 2.8180 - accuracy: 0.2620\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" posts something?\n",
      "The phone on Leigh’s d\"\n",
      " posts something?\n",
      "The phone on Leigh’s dame the sherer ther the th in the there de  her and thee there th lat se an thist. thes for  re thas.\n",
      "LEIGH\n",
      "IR Cond  an port ane her alle winn doud.\n",
      "Thint ane here sos the dere the  aog e s bing in yos mes thin shere sor the theat an the the ben ther ond there we s ant yof  for thes  he an the to the shenther s thet sol  (an that inn ine s tour the paig thes al yo that thar\n",
      "21/21 [==============================] - 91s 4s/step - loss: 2.8180 - categorical_crossentropy: 2.8180 - accuracy: 0.2620\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4567 - categorical_crossentropy: 2.4567 - accuracy: 0.3301\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"\n",
      "What’s it going to take to move it\n",
      "back\"\n",
      "\n",
      "What’s it going to take to move it\n",
      "backigh le ke fing the that in of the the te in s and so s lo tas doug thaly an s in lis at ale thid st an sout an dig wad sadis dist tout tot ine bing and the thes ig to lile sour facd at the salls are yor thed ouring waly ale you thing this tho  aud to the lle cor s and youl in that the te sond Oar tha the youd at that an wad saly ind coun tis at the d LEIGH\n",
      "(03. ERAD\n",
      "ERAD\n",
      "CONNER\n",
      "21/21 [==============================] - 91s 4s/step - loss: 2.4567 - categorical_crossentropy: 2.4567 - accuracy: 0.3301\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2514 - categorical_crossentropy: 2.2514 - accuracy: 0.3774\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"vation myself.\n",
      "MAITRE ‘D\n",
      "No, sir. It was\"\n",
      "vation myself.\n",
      "MAITRE ‘D\n",
      "No, sir. It wasd thit the ward war ly..\n",
      "MILO\n",
      "ONT. *\n",
      "AD.\n",
      "CONNER N - D Yer st to ton for to the sally ar me the dive dand so the pre ne wally te the wank ne and st a dist she was *\n",
      "LEIGH\n",
      "I’m and thand you Dere dis  ar y po thad to the ber s be bad the wave we t and her the les s and ther wald way. CONNER\n",
      "21/21 [==============================] - 92s 4s/step - loss: 2.2514 - categorical_crossentropy: 2.2514 - accuracy: 0.3774\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0821 - categorical_crossentropy: 2.0821 - accuracy: 0.4153\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"UICK CUT TO:\n",
      "55 55 EXT. RICHARDS REVIEW \"\n",
      "UICK CUT TO:\n",
      "55 55 EXT. RICHARDS REVIEW AND ERIN’S OFFICE- AND ERIN *\n",
      "ERIN\n",
      "So the the a dithe at it her some so wee you the wat in in the pee ere wat  of it go the whe whin and an hin she , in the bet the the har she is or if the in the er a lot on at it and to te to ding the at and whe waid to for is he he the thig the hic  ar the is ou come - NIGH\n",
      "(s ale  ou you an I me he the wit so a we whe com com *\n",
      "21/21 [==============================] - 90s 4s/step - loss: 2.0821 - categorical_crossentropy: 2.0821 - accuracy: 0.4153\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9610 - categorical_crossentropy: 1.9610 - accuracy: 0.4428\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"President?\n",
      "CONNER\n",
      "No! That’s too scary. \"\n",
      "President?\n",
      "CONNER\n",
      "No! That’s too scary. Leigh and to the able in to be har a lealle wer wall the the the serly the ano corling the teme ward at the to the are to ter and and betalling the at.\n",
      "CONNER\n",
      "Were the lat do the the ere her ee the  athind it on the tore the couplonting the peor at har to wer.\n",
      "BRAD\n",
      "21/21 [==============================] - 95s 5s/step - loss: 1.9610 - categorical_crossentropy: 1.9610 - accuracy: 0.4428 the sing to\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8652 - categorical_crossentropy: 1.8652 - accuracy: 0.4647\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ave a reservation!\n",
      "Conner looks at her.\n",
      "\"\n",
      "ave a reservation!\n",
      "Conner looks at her.\n",
      "CONNER\n",
      "Okeas)\n",
      "One past taand offoutan to the that shatt and...\n",
      "MILO\n",
      "On... *\n",
      "BRAD\n",
      "Ok to stanting and to stares a cae\n",
      "to sated the to the to stor it toon areasty.\n",
      "Bute to is offine.\n",
      "ERIN\n",
      "Okay. I im and toarouting intanten to stant to it.\n",
      "143 INT. to save that hand andonn and the you fing that wated a to the theo to bat ather and the offfing the tabee thas and thes offorues to and arout in...\n",
      "21/21 [==============================] - 109s 5s/step - loss: 1.8652 - categorical_crossentropy: 1.8652 - accuracy: 0.4647\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7893 - categorical_crossentropy: 1.7893 - accuracy: 0.4822\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" So I manage to not\n",
      "hyperventilate and t\"\n",
      " So I manage to not\n",
      "hyperventilate and to thes exppours the to meally the the to seer are and to and the the it a list to se the date the to hor somenger to mathing to and to maten to hever a seat the all the bott of the momes offite the sane. *\n",
      "LEIGH\n",
      "(thee in to her here the him her and the sauld to be a comees to to her thing to head torser it to hering to *\n",
      "her the shemed the that the racking to harmenot to her. *\n",
      "LEIGH\n",
      "21/21 [==============================] - 108s 5s/step - loss: 1.7893 - categorical_crossentropy: 1.7893 - accuracy: 0.4822\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7206 - categorical_crossentropy: 1.7206 - accuracy: 0.4991\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"its) *\n",
      "It was a disaster. *\n",
      "(MORE)\n",
      "Blue \"\n",
      "its) *\n",
      "It was a disaster. *\n",
      "(MORE)\n",
      "Blue Rev. (03/28/16) 6.\n",
      "CONNER\n",
      "She but kne that do it the if the come it you and the really dote ther it of just but the dote wat the dite the sitet *\n",
      "21/21 [==============================] - 128s 6s/step - loss: 1.7206 - categorical_crossentropy: 1.7206 - accuracy: 0.4991e the sate the potter whe to get the ret the s of the captite a for bat the bate the bat the pate the small the thing the call it t\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6558 - categorical_crossentropy: 1.6558 - accuracy: 0.5153\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e Leigh stands off\n",
      "to the side uncomfort\"\n",
      "e Leigh stands off\n",
      "to the side uncomfort on at beth of the happed takes the have the wass the on the the be we the sate.\n",
      "ALLISON\n",
      "(thenes heated)\n",
      "It heate the say.\n",
      "CONNER\n",
      "It the fauss the the the the reads the like the\n",
      "filleer the say.\n",
      "I know.\n",
      "CONNER\n",
      "It it not what the stoute.\n",
      "ALLISON\n",
      "Yeahe the shet we the stouse whites and going to down the pootty.\n",
      "MILO\n",
      "Yead...\n",
      "CONNER\n",
      "It’s the see at fropen the stallise that out out the stole.\n",
      "MILO\n",
      "21/21 [==============================] - 145s 7s/step - loss: 1.6558 - categorical_crossentropy: 1.6558 - accuracy: 0.5153\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6087 - categorical_crossentropy: 1.6087 - accuracy: 0.5265 \n",
      "----- Generating text after Epoch: 11\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" maybe you should leave.\n",
      "ERIN\n",
      "I’m not le\"\n",
      " maybe you should leave.\n",
      "ERIN\n",
      "I’m not lean the know a did Dad  on the comen the pare a arour back out the cor a meth the arous her are whe is love *\n",
      "the proct a becould so stay with a did you so deat in her our the want the did I’m say whit.\n",
      "LEIGH\n",
      "(smile to the read at the eave where\n",
      "tored.\n",
      "CONNER\n",
      "(orther her her a de’ve the sore\n",
      "the way the the prop to her were be the do and her thing her betty from our the this her\n",
      "21/21 [==============================] - 1487s 72s/step - loss: 1.6087 - categorical_crossentropy: 1.6087 - accuracy: 0.5265\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5641 - categorical_crossentropy: 1.5641 - accuracy: 0.5383 \n",
      "----- Generating text after Epoch: 12\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ble. Before she can get back, there is a\"\n",
      "ble. Before she can get back, there is a sick in a like a picking the reanser.\n",
      "CONNER\n",
      "Yeace you I mean you kever and I didn’t get a meant get her she comes at betty I wanted.\n",
      "LEIGH\n",
      "Why date the the sitce you *\n",
      "the comen over the that in you see it the can candsongeting to the date in the she up\n",
      "and it if it offices the becknow and you can the not you know going to caver and it’s of the you jutt an and can’t never and the bad wat\n",
      "21/21 [==============================] - 1611s 78s/step - loss: 1.5641 - categorical_crossentropy: 1.5641 - accuracy: 0.5383\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5202 - categorical_crossentropy: 1.5202 - accuracy: 0.5495 \n",
      "----- Generating text after Epoch: 13\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ork\n",
      "for The Peters Post.\n",
      "ALLISON\n",
      "(laughs\"\n",
      "ork\n",
      "for The Peters Post.\n",
      "ALLISON\n",
      "(laughs)\n",
      "“date we can’t her and the car a to hers be the he pages and and her her and the repporing then when the the set a doing to and the goors the be one here the paper arout of the table a sereant on the hell well whore thing to he sane of the good of the reading the\n",
      "21/21 [==============================] - 560s 26s/step - loss: 1.5202 - categorical_crossentropy: 1.5202 - accuracy: 0.5495e you he a\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4808 - categorical_crossentropy: 1.4808 - accuracy: 0.5601\n",
      "----- Generating text after Epoch: 14\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"art. Conner, looking *\n",
      "good, my friend. \"\n",
      "art. Conner, looking *\n",
      "good, my friend. *\n",
      "ERIN *\n",
      "(soops)\n",
      "We have see to what was sits to was to meating to was weat we have to meane to was the for out of the for the really tere for comes to was a to meares the sang to was with the same was dow at offers.\n",
      "Milo surser and sots offer and see the this is about my have to head smes about the sits to be it.\n",
      "CONNER\n",
      "21/21 [==============================] - 126s 6s/step - loss: 1.4808 - categorical_crossentropy: 1.4808 - accuracy: 0.5601\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4483 - categorical_crossentropy: 1.4483 - accuracy: 0.5671\n",
      "----- Generating text after Epoch: 15\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"uess it made me a little crazy.\n",
      "(beat)\n",
      "I\"\n",
      "uess it made me a little crazy.\n",
      "(beat)\n",
      "I’m strying the believe the for the gor of the scoper at the table there the gor and ster on the tame.\n",
      "LEIGH\n",
      "Okay. So what when she talks to me.\n",
      "BRAD\n",
      "What? I did of the Review what she’s her then we the her the reffer for the door go the really.\n",
      "LEIGH\n",
      "21/21 [==============================] - 125s 6s/step - loss: 1.4483 - categorical_crossentropy: 1.4483 - accuracy: 0.5671 the door and stard to the\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4145 - categorical_crossentropy: 1.4145 - accuracy: 0.5764\n",
      "----- Generating text after Epoch: 16\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ials her phone.\n",
      "ALLISON\n",
      "Hi. I need the n\"\n",
      "ials her phone.\n",
      "ALLISON\n",
      "Hi. I need the next to the to the Review write the *\n",
      "compreser off.\n",
      "ALLISON\n",
      "We don’t know.\n",
      "LEIGH\n",
      "The Gover to me to the Rachards Review and got and the it the really reading and the were her. I went were to the ned with the Revery to the king the Gempanted. *\n",
      "CONNER\n",
      "(beat)\n",
      "Well, I’ve the wers and to the Peters *\n",
      "to the crean a bad date to the the restate the reads to to the to to the Rev. (03/28/16) 78.\n",
      "21/21 [==============================] - 123s 6s/step - loss: 1.4145 - categorical_crossentropy: 1.4145 - accuracy: 0.5764\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3868 - categorical_crossentropy: 1.3868 - accuracy: 0.5832\n",
      "----- Generating text after Epoch: 17\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"s it back around to look at it, it is\n",
      "ba\"\n",
      "s it back around to look at it, it is\n",
      "bad date are still\n",
      "the bad date it mut must the rethat night and shres and sunt the late with a did your but it all shore the paper but the past and the table but whore have to shat reads here the restapp. *\n",
      "She have but for a moment.\n",
      "ALLISON\n",
      "(meats for one looks the looks at the daters are all she she the listly in the preblactas she last right?\n",
      "ALLISON\n",
      "21/21 [==============================] - 164s 8s/step - loss: 1.3868 - categorical_crossentropy: 1.3868 - accuracy: 0.5832\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3536 - categorical_crossentropy: 1.3536 - accuracy: 0.5929 \n",
      "----- Generating text after Epoch: 18\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"tablishing the offices of the Peters Pos\"\n",
      "tablishing the offices of the Peters Post. *\n",
      "Erin is are it’s not to been one.\n",
      "Milo looks and sorry.\n",
      "BRAD\n",
      "(beat)\n",
      "Well, to see the bad date.\n",
      "CONNER\n",
      "I’m sore going to look not. I was a company and no. I’m not and so around poon.\n",
      "BRAD\n",
      "I got and have to to now.\n",
      "Milo goes about...\n",
      "MILO\n",
      "(noted)\n",
      "Okay, I’m going to be a buinds.\n",
      "LEIGH\n",
      "I’m not...\n",
      "CONNER\n",
      "I'm going to be in to sight.\n",
      "MILO\n",
      "I’m not to be a door. I’m not a con’t been I reens... *\n",
      "21/21 [==============================] - 1442s 70s/step - loss: 1.3536 - categorical_crossentropy: 1.3536 - accuracy: 0.5929\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3336 - categorical_crossentropy: 1.3336 - accuracy: 0.5977 \n",
      "----- Generating text after Epoch: 19\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"*\n",
      "Establishing shot of Leigh & Erin’s ap\"\n",
      "*\n",
      "Establishing shot of Leigh & Erin’s apart\n",
      "know.\n",
      "LEIGH\n",
      "I was you want to walk and herelf at the carry.\n",
      "BRAD\n",
      "Oh at his here his a compacter.\n",
      "LEIGH\n",
      "Yeah, I do?\n",
      "ALLISON\n",
      "(noges)\n",
      "Then shakes at the pages and out on the table.\n",
      "She faied you and seep in the ready. *\n",
      "BRAD\n",
      "So wast a petty me aly and then should prote thing that\n",
      "21/21 [==============================] - 1430s 69s/step - loss: 1.3336 - categorical_crossentropy: 1.3336 - accuracy: 0.5977\n"
     ]
    }
   ],
   "source": [
    "text3 = text + text2\n",
    "chars = sorted(list(set(text3)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "seqlen = 40\n",
    "step = seqlen\n",
    "sentences = []\n",
    "for i in range(40, len(text) - seqlen - 1, step):\n",
    "    sentences.append(text[i: i + seqlen + 1])\n",
    "    \n",
    "\n",
    "x = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), seqlen, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, (char_in, char_out) in enumerate(zip(sentence[:-1], sentence[1:])):\n",
    "        x[i, t, char_indices[char_in]] = 1\n",
    "        y[i, t, char_indices[char_out]] = 1\n",
    "        \n",
    "        \n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "    preds = preds / np.sum(preds)                #\n",
    "    probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "    return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - seqlen - 1)\n",
    "    \n",
    "    for diversity in [0.5]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + seqlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "            \n",
    "            preds = model.predict(x_pred, verbose=0)\n",
    "            next_index = sample(preds[0, -1], diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            \n",
    "            \n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          callbacks=[print_callback])\n",
    "\n",
    "for i in range(len(model.layers)-1):\n",
    "    layer = model.layers[i]\n",
    "    layer.trainable = False\n",
    "          \n",
    "#model.fit(x, y,\n",
    "          #batch_size=128,\n",
    "          #epochs=150,\n",
    "          #callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What I am now going to relate is the history of the next two centuries.\n",
      "I shall describe what will happen, what must necessarily happen:\n",
      "_the triumph of Nihilism._ This history can be written already; for\n",
      "necessity itself is at work in bringing it about. This future is\n",
      "already proclaimed by a hundr\n"
     ]
    }
   ],
   "source": [
    "print(text2[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 3.7099 - categorical_crossentropy: 3.7099 - accuracy: 0.1329\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"reat that he actually does\n",
      "sacrifice som\"\n",
      "reat that he actually does\n",
      "sacrifice somet  ha   i  t s  tan  ht t c ie s  e  e  .e w n     reRe ao  t wh   erhst  aa ha Rd tse  e a o\n",
      " e es n i n  y. e n a i oio t     oaiwe ihe o wt  hks er   e    pt o I   o  se htehg . ae at\n",
      "ci\n",
      "\n",
      "t i e t n  hni .      s teag t e a rl i.e\n",
      "di t e  if  o    n   \n",
      " ae  e .  ati e  a, t r   we  wn eo  w  f o atar r  reewaasintheu lycal  ar is e  hahi,\n",
      " eie  e h i ere\n",
      "nnoeiey in i   elae\n",
      "s ..o  h h d oa tyo cetha it \n",
      "ea weani  a wt  t\n",
      " a)seeyr    n t tenerhe wae f ?o \n",
      " e a ea at at yaee ae to y   ’ee n \n",
      "mee  a bnt \n",
      " ahe ey   rashad ega ee wheral in r r  i hae ta ni ocai w\n",
      "I a  e     ree e e ce o \n",
      " laor   eh   it reeoh e aat o hh  s y ie ae h H Tent  nreamhy  m  \n",
      "u    t a a  ih g \n",
      "   et   le il. ehe.\n",
      "a   e  i at  ou fei\n",
      "\n",
      "o e  i a       t t   nhin     o Hn   tel hi te \n",
      "  a  en  n . ta  deiliee ’ a  n a ean  o e  et\n",
      " e ae hen   omeni on\n",
      "raa  e niN   ht Ih en dt es \n",
      "n  na h t  \n",
      "ei   r e w laewe \n",
      "h aea \n",
      "h .at \n",
      "  i  h  e o    y i  al ahen i  \n",
      "Oeae \n",
      "a hre uta \n",
      "efra .\n",
      " ee atei   o   h  n ’t e n  n dsve  o   ia.noan   ta\n",
      " A ine i a r a   in o iaecit a   re th t\n",
      " e\n",
      "r n\n",
      "d e i e tt\n",
      "o n e  e tce  ri   ityteie styow co  eee it  ii aale aat  Reer u.e e\n",
      "21/21 [==============================] - 179s 9s/step - loss: 3.7099 - categorical_crossentropy: 3.7099 - accuracy: 0.1329\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 3.1500 - categorical_crossentropy: 3.1500 - accuracy: 0.2006\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"specially hominum can probably amount on\"\n",
      "specially hominum can probably amount on in  eo   e  a t ou fei e e e s ae  he  he t s ae to ee . in  e  y be  ein  ae  he  o y ae . (e  e le   e  he bhe p the  re  eo  ae the  a  ane the ie to s\n",
      "ap  e  e  o\n",
      "   e ce  an e R L ea  ou . Ren uor o e  e  a   o  e i e t. to pe be d me rin  he ia  ak  ae  io  e e  e i  ee  t e  a e ae ie  o  oe re ie teee the   ar e ae os t te \n",
      "ie  ie  le   ous we  yoy the y woN  y  oa  ae  one an  ee Eou . ie the t ae afee e y  e t a te  e  ha ae  iu  e  o  e te  i le tee  ie  he  le e \n",
      "o d to t a s on e ao  ie s cau so o y s ke  e . to  ae  o  f dabe an the come wo rit e u ie  ou  e te no a   e io  he the coy \n",
      "e n  e e s out an  he reout.\n",
      "L he e  ou  ou  a k  we  e  a  are fou e ce  e  or eo in e ie e  ie in  ie  ou  ire  ep t w  e do g r au   o .\n",
      "ie y to .\n",
      "we le teree e th ao e  o eine oo  e  ae e be  in  ou ill y le  e \n",
      "e e  oo e  ie - oe we are f t ie me, o a  ee  aris  e e thea re a e ao y ut the we s ae  e i e \n",
      "e iine the  e te   e al he e we . ae ce  o  akes a le .\n",
      "oei  o ae  io  ou  e te thee s ue e be ou le wo re  e e e y oue he e the i is Io nou  o   it tare  ou be to ne ia  ou  in t ae e toe e  o e res  e t ur ke  ae o   ai.\n",
      "A t as\n",
      "\n",
      "ae  oe   uo   a\n",
      "a se ire .\n",
      "21/21 [==============================] - 185s 9s/step - loss: 3.1500 - categorical_crossentropy: 3.1500 - accuracy: 0.2006\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.6440 - categorical_crossentropy: 2.6440 - accuracy: 0.2942\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" to\n",
      "ordinary men, to the majority of the\"\n",
      " to\n",
      "ordinary men, to the majority of the the we he we  he.\n",
      "CONNALER\n",
      "Whe\n",
      " LEIGH\n",
      "ALTANER\n",
      "CONN\n",
      "ER\n",
      "Y *\n",
      "Whe ERACON\n",
      "YoT\n",
      "ISONNERAD\n",
      "AR\n",
      "ONT *\n",
      "Whe Ae ce *\n",
      "CONNER\n",
      "CONER\n",
      "D *\n",
      "CON\n",
      "The  ale he to he Lere ou\n",
      "re \n",
      "he d ghe *\n",
      "INNER\n",
      "The the ro  ou  he dio  ho  he \n",
      "The  he he tou re the e he he the de che he Whe he gon  he the’d *\n",
      "CONN\n",
      "Son the \n",
      "ou *\n",
      "ALISON\n",
      "Wh ao a he ghe ER\n",
      "IS\n",
      "CONNNER\n",
      "AT\n",
      "YoN\n",
      "(INNN\n",
      "CY\n",
      "CONN R\n",
      "D\n",
      "IS\n",
      "ONNER\n",
      "SON\n",
      "ER\n",
      "Y\n",
      "AONTTon AER\n",
      "RAN’CONNT\n",
      "AAN\n",
      "Whe the the  he d the he she  ou he you  or CONNR\n",
      "SONNON\n",
      "(CONNER\n",
      "Alt er\n",
      "TER\n",
      "CON\n",
      "(aL *\n",
      "LEIGHT\n",
      "LER\n",
      "SON\n",
      "ERALER\n",
      "AR\n",
      "I ’  D\n",
      "BR\n",
      "ER\n",
      "T IGH\n",
      "The bou\n",
      " hon dhin .\n",
      "BR S *\n",
      "CONNERAY\n",
      "Y\n",
      "Whe \n",
      "R\n",
      "MIGH\n",
      "D\n",
      "LEIGH\n",
      "CONNER\n",
      "S RISONNER\n",
      "SO\n",
      "- D\n",
      "Thes *\n",
      "ERAS - *\n",
      "CONNT\n",
      "NEIN\n",
      "CONNER\n",
      "D\n",
      "LON\n",
      "Thin de She the o d To e he \n",
      "IGHT *\n",
      "It *\n",
      "CONNTTT *\n",
      "(SON\n",
      "T the *\n",
      "IL\n",
      "ER\n",
      "We  he the .\n",
      "CONNER\n",
      "Y\n",
      "LON\n",
      "Whs D\n",
      "CONNER\n",
      "SON ER\n",
      "CONNT *\n",
      "You  o  o  he  oo  ou the det *\n",
      "CONN\n",
      "ER\n",
      "LEIGH\n",
      "CON\n",
      "Y\n",
      "INNER\n",
      "ER\n",
      "ANT.\n",
      "INN\n",
      "ER\n",
      "N\n",
      "The.\n",
      "Whe ’t *\n",
      "You s ind he the he in  oo d yhh .\n",
      "LEIGH\n",
      "Yhan *\n",
      "N ONNER\n",
      "N I’T *\n",
      "BRAD\n",
      "The ER\n",
      "RONNER\n",
      "ER\n",
      "SAT AONTR\n",
      "ERAD\n",
      "SON\n",
      "(CON\n",
      "(CONNER\n",
      "You ER\n",
      "CONN\n",
      "RoNTER\n",
      "LONN\n",
      "Whe b ou H\n",
      "*\n",
      "CONNNER\n",
      "A\n",
      "The\n",
      "BR\n",
      "Y\n",
      "NER\n",
      "ER\n",
      "D\n",
      "The tof Lhe e *\n",
      "MIN\n",
      "Whe’ ou ghe  oe A (0 the u on che the the pe the IT\n",
      "LOGH\n",
      "CONNER\n",
      "AD\n",
      "R\n",
      "Yo ’s Eoo the wo c in’ so de he d *\n",
      "21/21 [==============================] - 180s 9s/step - loss: 2.6440 - categorical_crossentropy: 2.6440 - accuracy: 0.2942\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3547 - categorical_crossentropy: 2.3547 - accuracy: 0.3476\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"philosophical humour has left him. The\n",
      "m\"\n",
      "philosophical humour has left him. The\n",
      "merde dont thand thes lon the d thadl *\n",
      "I *\n",
      "BRAD\n",
      "BRAD\n",
      "Whand the domllllll ighe the ching shing shers thend shing the doulllles thelld the lloug and the the that lout the der and *\n",
      "I met thelll then thing the shellling the badld sher the thing oron dont dinnd toullly *\n",
      "Brin’t therd the buthand wat the thend *\n",
      "You thing the yoursot I cad thand ret sis shend *\n",
      "*\n",
      "ICON\n",
      "Yon shallllllling I’s thind she toullllly the but thit  hat n lllly thing ous and the dith the doon the dores the pecly puthire ther the the the d and the copllls *\n",
      "I *\n",
      "Alllllld you chind the then.\n",
      "ICONNER\n",
      "Shellls the dofres fis thallls *\n",
      "*\n",
      "LEIGH\n",
      "ERIN\n",
      "(03/28/16) 100...\n",
      "ERIGH\n",
      "(rer the thing mid shend the dilllllid ind bes thon thend reve domet thend thand\n",
      "delly *\n",
      "I’m *\n",
      "IN\n",
      "ERIN\n",
      "Whand thend ntre hat thand Ime donke er lume no thy thats she thing thinge. *\n",
      "LEIGH\n",
      "Whe d therllllll sored ther the the haclllllly *\n",
      "(reellll, I chand the ke at the lling theve thoulllyof the the thend thacke the the chat and ther.\n",
      "MEIGH\n",
      "ERAY\n",
      "Whand Con’m thend of therllle thinnter *\n",
      "CONNER\n",
      "You LEIGH\n",
      "(03/16))\n",
      "103/120 55.\n",
      "EXT.\n",
      "(CONNER\n",
      "(CONNER\n",
      "(sdut hor s delllllllllllllly *\n",
      "CONNER\n",
      "Y\n",
      "AD *\n",
      "ERIN\n",
      "You the dhet.\n",
      "MILO\n",
      "CON\n",
      "ER\n",
      "(CONNER\n",
      "21/21 [==============================] - 171s 8s/step - loss: 2.3547 - categorical_crossentropy: 2.3547 - accuracy: 0.3476\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1614 - categorical_crossentropy: 2.1614 - accuracy: 0.3949\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"re, is lost sight of: modern scientific \"\n",
      "re, is lost sight of: modern scientific s e ou the he the to  of the wand no wan the the go the wang the the be the t t the the wap the the we the to the dou go the the brit and the d on to the the he the the le to the  of the the the do th the do to to the to we the sats to the to ou do se the the the he pur t is the he wing you go the cou go the sre do to the the the he the the the do the to the the to to he the to he the wat s the so wing an the on he put the she so the gers the to the to  of re do the the the way thes she to se the sto you set and the dor to to to the the s the to the The the to the ho he to the poo so go to the to er the che the an he se the we to the to se she the for st we sing in the he wad the to the Milo goe she for the so the der and you ge so the go thes we t ang ou you the the the won to the we co ser so e d the the ho the de the we ding the go to the cout.\n",
      "ERIN\n",
      "(CONNER\n",
      "Er and.\n",
      "ER\n",
      "S DADALEIGH\n",
      "AND ERANT - DIGHT I d and *\n",
      "ALLISON\n",
      "Er an the the hing the he che ne the whe to dou he do the go the som to to go the to to s in we do the bro you the se the we th the the to the to the no the the\n",
      "21/21 [==============================] - 184s 9s/step - loss: 2.1614 - categorical_crossentropy: 2.1614 - accuracy: 0.3949\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0009 - categorical_crossentropy: 2.0009 - accuracy: 0.4319\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ense, is something so thoroughly unnatur\"\n",
      "ense, is something so thoroughly unnature the pate a af are the sadt a dath are *\n",
      "leithay hare hare here are the wathe for the hame a but ou piofe it mo a a ou wate the tha be the dor a tat cure ar at aur at the hare are are the the couther but thabe a for a bus oup the the puthe wathe auteali out the ther he he to the have her hare haree are sure but of the thot are are te the her the the hare to the offres are and sore that a but ay the bis in the back ou arat but The tare I but head *\n",
      " ofine Reve the being and the talle a pune hat eale a latere you beat ouprare appust our and that a but are her are *\n",
      "anpering a date waie a the tay here the sate wable our hare for a a bate at the to the the hat a but her the saa but sime reates is to bead and af as ou the ceme are are har of whan a cauke the pit wat a aut it the har a aupach the the bate a tate ire aring are gate of the the care a but hare hare heme *\n",
      "peete sare an the sate the sire pure of the but as amay a af chet areather at a fout the cound her and *\n",
      "thire are beadine is tare are the har *\n",
      "oure af a dome are abe the but at a foure bite and har the but are the toule *\n",
      "21/21 [==============================] - 179s 9s/step - loss: 2.0009 - categorical_crossentropy: 2.0009 - accuracy: 0.4319\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8854 - categorical_crossentropy: 1.8854 - accuracy: 0.4612\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"present-day\n",
      "knowledge, cannot fail to se\"\n",
      "present-day\n",
      "knowledge, cannot fail to serle the cerene I done the leads I comped... I do ling. *\n",
      "CONNER\n",
      "He do sers sore.\n",
      "LEIGH\n",
      "Yead bestere songes astere!\n",
      "MILO\n",
      "You’de Conner.\n",
      "CONNER\n",
      "You dere you’re\n",
      "ne...\n",
      "ERIN\n",
      "I den’s besting to be.\n",
      "LEIGH\n",
      "I deskn the beally, then sere and wand on to leed in somes cher.\n",
      "MILO\n",
      "So connere the becands then\n",
      "MILO\n",
      "I wanne werre des.\n",
      "CONNER\n",
      "He the don’e then fred and conner.\n",
      "ERIN\n",
      "I don. *\n",
      "I conner and and thend bectonge on and wute some comem.\n",
      "CONNER\n",
      "Andy non.\n",
      "BRAD\n",
      "Milo I donnere.\n",
      "MILO\n",
      "I donking sore bust.\n",
      "CONNER\n",
      "Ally best.\n",
      "CONNER\n",
      "Milo silles and the letser ares menes.\n",
      "CONNER\n",
      "I don’s then I beade the on the bates bred. ALLISON\n",
      "Yeur.\n",
      "LEIGH\n",
      "You were be just and *\n",
      "Blue Rev. (03/28/16) 14.\n",
      "ALLISON\n",
      "I’m not. Conner to herle to be the firs mest.\n",
      "CONNER\n",
      "Hey.... ALLISON\n",
      "Thes menges)\n",
      "Brad on core to be.\n",
      "ERIN\n",
      "Go don’t beades and to ke fere cand.\n",
      "CONNER\n",
      "But sing sere in then.\n",
      "MILO\n",
      "You’re going the kerer I danl hers mend best the is the mere your as the king.\n",
      "MILO\n",
      "Yes the cond nome beade us\n",
      "lad st looks were be conner and be...\n",
      "BRAD\n",
      "Sher sore seres on tre compuren herres. *\n",
      "CONNER\n",
      "Sory nome mere.\n",
      "CONNER\n",
      "I dinks shat\n",
      "mesten is and somes on the chapses here you beclo.\n",
      "ERIN\n",
      "(ries)\n",
      "BRAD\n",
      "21/21 [==============================] - 174s 8s/step - loss: 1.8854 - categorical_crossentropy: 1.8854 - accuracy: 0.4612\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7991 - categorical_crossentropy: 1.7991 - accuracy: 0.4795\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ach must _postulate_ a goal\n",
      "for himself.\"\n",
      "ach must _postulate_ a goal\n",
      "for himself.\n",
      "MILO\n",
      "(CONT’D)\n",
      "Yes the hawe to she kin is the her the rasther a bee to the lies a be the smome you her his ay hare a wat on the pit the read the par to your a reat the was it a mo\n",
      "till on whis it sis is the poigh him om a chor a her thet\n",
      "is the reowe is to the hag\n",
      "s of the pears she her was to wis cour her the hat of the purs this a mo a pit the rere what the beed of the there fill the riig a bae sto is wit is you dint hio sire the rice the was you the reat sim hap the patt is ste ming the on the seer a reo the reith the this to this lis the his the rich and the rook a sits the his the withing I\n",
      "fires if this sit the his the way this the ris wait the rerering the read cofer and the hick of a pees of the sits of tielising this the reat the his wing the reow a he was a somes the is the on where wing the real comes is it the lighing the pattor a just biks this somer him this was going they the contire a was it the pust in on you and wappater his sit to the rion the reich to a comes it to to Leigh ware the sith simes a pit she sor the but bot a mich a somen the pise to the has the reat is the reas is the ret\n",
      "21/21 [==============================] - 191s 9s/step - loss: 1.7991 - categorical_crossentropy: 1.7991 - accuracy: 0.4795\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7190 - categorical_crossentropy: 1.7190 - accuracy: 0.5007\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"pen all prison doors.\n",
      "\n",
      "Still art thou a \"\n",
      "pen all prison doors.\n",
      "\n",
      "Still art thou a bate. *\n",
      "LEIGH AND ERIN *\n",
      "(she serint a pate to somether and *\n",
      "Leigh soing a sate seat the Petile and *\n",
      "ALLISON *\n",
      "The heart to beta back to to this to the hand to the reare you had on to me a site aring to way to in wast to bo the stat a can and to so\n",
      "stapes waiting on the Peters on the hast to to way his a like to the *\n",
      "Leigh say the Pete to to you late to to the *\n",
      "Brad *\n",
      "it's for a can the Petery for a paiting to to to stoure hither is ar and sore and *\n",
      "and we look on the Post on the Peting and to to\n",
      "enting to in our on the gooo.\n",
      "Leigh past that to site it and conner and to to say and to the dite look in the Recine in the Peter and Son’t pring a matter to start on the Petre and the look really in to so like at to the have to ere and *\n",
      "Leigh so recars to in the Pote sithat on of the to\n",
      "do stard to late fireer onting the *\n",
      "Leigh seast you dote to the wate to store and *\n",
      "Bluick you and to in a read a pathe in the resters and to the Alliso to in to stire to the have to the tomer and to\n",
      "head my to en to the to *\n",
      "hat of to in the Peting the fortore on this on the Revie taybe to eppecers you in or the paits it dote to fine so the Pothe it\n",
      "the Poter and to\n",
      "21/21 [==============================] - 188s 9s/step - loss: 1.7190 - categorical_crossentropy: 1.7190 - accuracy: 0.5007\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6515 - categorical_crossentropy: 1.6515 - accuracy: 0.5175\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"excitement,\n",
      "of patriotic anguish, and al\"\n",
      "excitement,\n",
      "of patriotic anguish, and all the soment of the cempiter and the soort to be ald.\n",
      "LEIGH\n",
      "No.\n",
      "MILO\n",
      "And she the read\n",
      "of the becked a meally shough and all going that the see it wer it the her to fre all her the now the pares to the table to in mestere the compurped and the table that Leigh ser the ham and the compresseds and the table we to gen the stere are the her doe and the cally the peren the have on the the\n",
      "camponer be the siter and stors be\n",
      "the really the compune the really on the ther stardy and can the secheres she\n",
      "ever the restars compone.\n",
      "CONNER\n",
      "I thind the palle to the *\n",
      "the to be to bet the can the smare that is the capponer.\n",
      "LEIGH\n",
      "(bad I that do det in is ald the the same\n",
      "and the beade the mare\n",
      "them at the Mille the it.\n",
      "LEIGH\n",
      "Allison all is the seace and Conner dree the eder the seere be the ster\n",
      "the ereed from all on the pringe and palle a wereer on the campules.\n",
      "MILO\n",
      "Allison’t a seall be the cap realy and *\n",
      "the parter of the haver bet out and and waining the ser and this be fer and you ser\n",
      "becande and really fremet on the pares do des\n",
      "and the womene the really the gut the reading the bad can the as a reend her was not the peter and the mally\n",
      "21/21 [==============================] - 241s 12s/step - loss: 1.6515 - categorical_crossentropy: 1.6515 - accuracy: 0.5175\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5945 - categorical_crossentropy: 1.5945 - accuracy: 0.5320\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"tic outlook,\n",
      "the mistrust of the riddle \"\n",
      "tic outlook,\n",
      "the mistrust of the riddle the was make with the computer her the back the call\n",
      "bad the rithed hat the pastat is the was the Peter\n",
      "out and here a meate with is on his moment in her\n",
      "shut were.\n",
      "LEIGH\n",
      "She can it you gind the chat the wast the have the sided a wastige the whot a dit sitting buck it the him hes the whit was wirk a pits it\n",
      "it the put a but the the cand the Petich at the chat me him wasther him hem for a chat it just the can the reat the has me the waste it shot and the cheir in is she\n",
      "shands the thours the buttat a batt the wast the with\n",
      "and out of the coppetting the but I wit her what\n",
      "did.\n",
      "BRAD\n",
      "Sore whot you his when I’m start what the Peter her the *\n",
      "and the kand a car and the caut the wash.\n",
      "What are you his wilk you a cid the pits the has the fits it a wast the cam the cond the his the chat the ride the car and she sitce a computer the fice to the wast the Richir shot when his ham the wast of how storfine?\n",
      "LEIGH\n",
      "And I’m sure thit was like of the hat it the cuppine they wast the call of the his *\n",
      "micher her the better.\n",
      "ALLISON\n",
      "What want you just the was with the his the table and *\n",
      "cunce.\n",
      "ALLISON\n",
      "The rid. I dint you and the matting the himp the can her the camputer.\n",
      "LEIGH\n",
      "21/21 [==============================] - 334s 16s/step - loss: 1.5945 - categorical_crossentropy: 1.5945 - accuracy: 0.5320\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5436 - categorical_crossentropy: 1.5436 - accuracy: 0.5448\n",
      "----- Generating text after Epoch: 11\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"o the\n",
      "place where it starts; or he treat\"\n",
      "o the\n",
      "place where it starts; or he treat the really.\n",
      "LEIGH\n",
      "AND I (CONT’D)\n",
      "She’s going the the came and then here pore.\n",
      "BRAD\n",
      "This is sime the expecen *\n",
      "with the porter a beenther a bare the reare.\n",
      "MILO\n",
      "A did I wanter and to the care. *\n",
      "Leigh was lom of the table was Milo las and the computer back the\n",
      "really then wat the computer the computer on the back to go the tables a *\n",
      "will on the computer and the expers bith waste mesing of the computer of the bater and then I was realing the expiter is the computer to the canction a bat the waste it a more in the compor on the paper of the table then of the campther all the a with with filles of the\n",
      "the reng a light and then the computer of Leigh\n",
      "nothing of the table to sho this where and Leigh and then is with were is of the back thing that when stups with me both whing his leats of the can with make up on the palls.\n",
      "BRAD\n",
      "(reaks the going the wenter and then I mentor.\n",
      "ALLISON\n",
      "Leigh with me going then all be a low a mater whes *\n",
      "hingle going mo *\n",
      "what dithing to go then I really fing.\n",
      "CONNER\n",
      "Deas I table about of the for the are offres and her and the whine and *\n",
      "chat are the computer *\n",
      "the\n",
      "cact of me and the comment of the table then I was when I man it to\n",
      "like, frow *\n",
      "21/21 [==============================] - 312s 15s/step - loss: 1.5436 - categorical_crossentropy: 1.5436 - accuracy: 0.5448\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4982 - categorical_crossentropy: 1.4982 - accuracy: 0.5565\n",
      "----- Generating text after Epoch: 12\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"sical music\n",
      "besides. Dramatists are cons\"\n",
      "sical music\n",
      "besides. Dramatists are consers they the doon that mean a to the stores and then is it here her the cally the could and then then here it on the hise be to was neally the *\n",
      "then the goon his stoted the throng the ering.\n",
      "CONNER\n",
      "I’m sorrying to seat the one of the car a sitel shoke the sed the seever the here was it the what deter at her starts the stort the then it was a cough to the tho ght the shen it was we the the could watching the shupt of the computer\n",
      "the sore out the store her to the car were of the car.\n",
      "CONNER\n",
      "I can’t counted the palls of the stalling the chat out with the potcres and the stappecter and then the parts the stand the sithe stoping prone and the\n",
      "dook her.\n",
      "CONNER\n",
      "Because I’m not we really that see the thought you’re then the going the sothing then the chat stopering of the chat is theie white the phone she really that\n",
      "Conner and then it this be it it her heard you’re you’re ner and then is the deters a dealing the beally on the table to concher and then the shat the sereelly the saice it. It’s for a worked the wast the then on the nothing the realy the stally to Leigh wat was here pronge thought’s think the stores the stere and the wast. *\n",
      "BRAD\n",
      "21/21 [==============================] - 345s 17s/step - loss: 1.4982 - categorical_crossentropy: 1.4982 - accuracy: 0.5565\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4608 - categorical_crossentropy: 1.4608 - accuracy: 0.5663\n",
      "----- Generating text after Epoch: 13\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"will be those of\n",
      "duty: that reverence, w\"\n",
      "will be those of\n",
      "duty: that reverence, wattent the puts to well we tho it’s overtands of I was what\n",
      "show do shards Richards Review of the could and Erin goes and Conner all when you\n",
      "have you going to in that out you’re purst of the table betires and *\n",
      "here and I can’t you’re her in that’s goe the way and she puts a ple some to go and eap...\n",
      "CONNER\n",
      "Okay. It’s ake you. I was whene a cooputer. *\n",
      "CONNER\n",
      "I was you wetters and stards date it.\n",
      "CONNER\n",
      "I to that’s you, do?\n",
      "LEIGH\n",
      "I’m stakes to side and we putche its out of the computer on the computer and the cons a put the come to looks of the waited a could\n",
      "leave you here sture and that when the pughtare and *\n",
      "could we don’t was the could to I car she sure of the louph one her. *\n",
      "MILO’S OFFICE - DAY\n",
      "Establisoing and It’s ake we wat herserters I have the cad\n",
      "and Erin is ourd.\n",
      "MILO\n",
      "Yeah, you know it and *\n",
      "way. I was what you mean the look and coull betwer and *\n",
      "that date is the have to mean stard *\n",
      "that whate I\n",
      "have you way. It’s office and puts and *\n",
      "the lake.\n",
      "LEIGH\n",
      "What’s akisting.\n",
      "MILO\n",
      "Oh you do?\n",
      "LEIGH\n",
      "I\n",
      "head you do in the really. It’s a did you got that.\n",
      "Conner and Conner\n",
      "had.\n",
      "LEIGH\n",
      "I was go and heads bad the puts so what the kits the caullers it are\n",
      "have sto stard to look.\n",
      "21/21 [==============================] - 195s 9s/step - loss: 1.4608 - categorical_crossentropy: 1.4608 - accuracy: 0.5663\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4190 - categorical_crossentropy: 1.4190 - accuracy: 0.5767\n",
      "----- Generating text after Epoch: 14\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"X\n",
      "\n",
      "                     SONGS OF PRINCE \"\n",
      "X\n",
      "\n",
      "                     SONGS OF PRINCE - DAY\n",
      "Allison going to sid on to work bud your bad say of it. Sorry... worne it.\n",
      "LEIGH (V.O.)\n",
      "What don’t your beire as all for the down the a card. It’s now you look at the late was and\n",
      "your fare was a really was a lide. It’s sore and the oullien and started sauly.\n",
      "MILO\n",
      "(shakes and stoping of the going you sers and sand\n",
      "reading but you went do sall is office. But I’m going to be ware was a\n",
      "like way too of if the down to were bad to ser out of the office and happened... CONNER\n",
      "You was want to be a wanted tow it. She stiles and she has a towally?\n",
      "MILO\n",
      "(smile)\n",
      "Son you going tome to be a pote bad your towe was the eaplent of the to bad a moment and happen and she say in the fore bood about wait of the could going to wark your bad sure toward was a bor to is to have to be wast halde was a for you don’t could cally blog and really just to go date walking at more and she say bad date have you sery and you selise date you sew a and walk to say to more with and was your same your bud the rend and was happent and you sen thing to say\n",
      "eater tay. *\n",
      "ERIN\n",
      "(sares) *\n",
      "“They was while is the stual is fine. Your out of the forably walking of it.\n",
      "ALLISON\n",
      "(reads) *\n",
      "“The don’t sell we was blinted it.\n",
      "21/21 [==============================] - 188s 9s/step - loss: 1.4190 - categorical_crossentropy: 1.4190 - accuracy: 0.5767\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3869 - categorical_crossentropy: 1.3869 - accuracy: 0.5841\n",
      "----- Generating text after Epoch: 15\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"enious devices in the first scenes to pl\"\n",
      "enious devices in the first scenes to ple to the can the chat that we sow the table. *\n",
      "CONNER\n",
      "What do you me just we sar the the table to frou computer to the computer to the have come that the come to the chot the table the a metter to the computer to come that he see to the tay the been whe have to me to\n",
      "say to me to see it to the to a make a moment of the cormet her a really her because I'm she to was the who the table and the to the real be to te to see to the compect wastane the start to the to be to be to the computer her to were better to the table to ste to be to wo be to the to do you meen when the computer we could the to sit of jeat to de look to the computer and sure to me to be to the a back to me a fewe to be to be to wait to make to say the our for a was really to bate to me to me to the the better to the corund dest of the table to me a but to be were you here to the table the see that we to be to meal back to so *\n",
      "21/21 [==============================] - 186s 9s/step - loss: 1.3869 - categorical_crossentropy: 1.3869 - accuracy: 0.5841so really were better to be to the door a deter a reters to the both and see to the back to the table and the table to the see the the she ters the to be to the computer to\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3577 - categorical_crossentropy: 1.3577 - accuracy: 0.5908\n",
      "----- Generating text after Epoch: 16\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"c ideal with equal fervour,\n",
      "which uses t\"\n",
      "c ideal with equal fervour,\n",
      "which uses there in all them down to Leigh and Conner inst the cand to the rent any of them and them them. I don’t think to been he do come to som of the computer and peess one to sare them in of the rest of the wait. *\n",
      "INT. CONNER\n",
      "I know you to be the bad doing to sig.\n",
      "Milo and Conner’s going to go to do on the pooned of a waind to go to do shirt good and the bad bad dates them the restly\n",
      "but I not it going to go table to say of theme so right go\n",
      "for a moment that a moment to say this pant to sig.\n",
      "CONNER\n",
      "I know...\n",
      "CONNER\n",
      "I know. And walking to homputer.\n",
      "BRAD\n",
      "I’m not looking and then she this is in. It’s for theme, them what the peest but the door for a rest but them. *\n",
      "EIGH (CONT’D)\n",
      "Blue Rev. (03/28/16) 62.\n",
      "120 102 EXT. CONNER AND BRAD’S OFFICE - DAY\n",
      "Conner’s same to see the some have something to do theme.\n",
      "CONNER\n",
      "I don’t know. I was need them... hers. This is realling.\n",
      "MILO\n",
      "(and)\n",
      "Why was not this this wain need the\n",
      "computer. *\n",
      "INT. CONNER\n",
      "I’m going to do som\n",
      "off the come to me to got to leave this.\n",
      "LEIGH\n",
      "I don’t going to meen them\n",
      "write doing to rever\n",
      "bad dates but has and hers going to smile for a moment to them a recerfers to her here rever and then she they were look those of her\n",
      "21/21 [==============================] - 195s 9s/step - loss: 1.3577 - categorical_crossentropy: 1.3577 - accuracy: 0.5908\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3265 - categorical_crossentropy: 1.3265 - accuracy: 0.6000\n",
      "----- Generating text after Epoch: 17\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"hem,\n",
      "and by again and again calling atte\"\n",
      "hem,\n",
      "and by again and again calling atters.\n",
      "LEIGH\n",
      "It’s some becouse it out now a beding *\n",
      "him she table to the smiling...\n",
      "CONNER\n",
      "Incond and that’s my from the fallole.\n",
      "LEIGH\n",
      "I’m not that are frout it’s my breat that may she smiles to the computer this way.\n",
      "BRAD\n",
      "I’m lough and Erin are you’re things to say that *\n",
      "you inverse of the staging out of that.\n",
      "BRAD\n",
      "I’m not in outdose bad stay. *\n",
      "It’s be wry, I have for a bad date a meal me was.\n",
      "CONNER\n",
      "It’s that I taybe from the computer\n",
      "the back to the carry going to mutall bud the restaurant my are you’re some for a back this.\n",
      "CONNER\n",
      "What you grid date. *\n",
      "Leigh and Allison.\n",
      "ALLISON\n",
      "Tound out of the bid because to the stap of the bad bad a would walk to the rast\n",
      "call be has thind *\n",
      "was a car and palls out of the door a back that *\n",
      "you’rd the rest up...\n",
      "LEIGH\n",
      "I that? Okay... (03/28/16) 11.\n",
      "ERIN\n",
      "That’s the bost.\n",
      "LEIGH\n",
      "Itw the table and then starts to I was bloge.\n",
      "CONNER\n",
      "In what’s going to think. *\n",
      "It’s just think to the date.\n",
      "ERIN\n",
      "Thanks to make in a mad *\n",
      "chair. *\n",
      "It’s fine. What? No. I way think I’m something? What are you have that’s office in the cad.\n",
      "LEIGH\n",
      "In way have of the pably latty thing *\n",
      "up the table a waiter. *\n",
      "BRAD *\n",
      "They have a retide.\n",
      "ERIN\n",
      "21/21 [==============================] - 190s 9s/step - loss: 1.3265 - categorical_crossentropy: 1.3265 - accuracy: 0.6000\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3005 - categorical_crossentropy: 1.3005 - accuracy: 0.6072\n",
      "----- Generating text after Epoch: 18\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"led the furthest with the nearest, fire \"\n",
      "led the furthest with the nearest, fire it to do start down a\n",
      "dide. No.\n",
      "ALLISON\n",
      "And you talks it to good fire to the computer going to frea complet down at the computer *\n",
      "Leigh is start of then INT. RESTAURANT - NIGHT\n",
      "Erin is to see the stant to smile in the door and then just is puts dates up to do stop dates and em to thing that the computer *\n",
      "well then she stance and he don’t got in to the door on the waiter, so.\n",
      "ALLISON\n",
      "I can’t eat of the door and Conner is the could *\n",
      "and then it to the comple\n",
      "first desk on the computer it to\n",
      "the office it the start to me now reading with we wat he frong the door show the door *\n",
      "like the date of a give. *\n",
      "ALLISON\n",
      "He think the resore what I\n",
      "was the door date it to start of care for a moment, then start to say the rood to leilt.\n",
      "ALLISON\n",
      "And we rues and then it was just a date. Do you\n",
      "me do.\n",
      "ALLISON\n",
      "And we stop in the know. I don’t you like where the table to the some his do she stop on the table to start to mealy.\n",
      "ALLISON\n",
      "And we starts a did there to inte from to the rest in the date with a something what you figure good and then the poop...\n",
      "ALLISON\n",
      "I dat? How you’re going to say thing to paper when I was the bat *\n",
      "21/21 [==============================] - 197s 10s/step - loss: 1.3005 - categorical_crossentropy: 1.3005 - accuracy: 0.6072\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2748 - categorical_crossentropy: 1.2748 - accuracy: 0.6135\n",
      "----- Generating text after Epoch: 19\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"course, wherever Christianity prospers\n",
      "a\"\n",
      "course, wherever Christianity prospers\n",
      "and then it like that the was one of the could her to make it the could It’s the could on the car and the same toward the was a chote the concrett that\n",
      "it is the kit it wo could think the book down the waiter the betted toward the car and to see the could *\n",
      "explaition his thing and then the coult like this hat me a smert her to mean in the could\n",
      "can *\n",
      "the other and then the car and the could he have that\n",
      "it’s eyters to sit of the car were\n",
      "with the conches to sit it to the was a moment the could her acroompy. I’m sorry for the could *\n",
      "the carmantice and the story conther the office in the chuight back and then the kitchen the has in the know whate you’re going to the couch other the table and the other her\n",
      "the one of the could *\n",
      "trying to see this we car a resk on fire to meen the could *\n",
      "with to see the couch one of the good down to see this the bother bad date with the could to see this into the could the *\n",
      "the cauchat she was the far the one of the car and take it care the door the car reading at the table this is the know we it to the could ton the too at to wore thing to be a\n",
      "21/21 [==============================] - 258s 13s/step - loss: 1.2748 - categorical_crossentropy: 1.2748 - accuracy: 0.6135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b2f231660>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    " \n",
    "for i in range(40, len(text2) - seqlen - 1, step):\n",
    "    sentences.append(text2[i: i + seqlen + 1])\n",
    "    \n",
    "        \n",
    "model2 = Sequential()\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "model2.add(model)\n",
    "\n",
    "model2.add(LSTM(128, input_shape=(seqlen, len(chars)), return_sequences=True))\n",
    "model2.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "\n",
    "model2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=0.01),\n",
    "    metrics=['categorical_crossentropy', 'accuracy']\n",
    ")\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.exp(np.log(preds) / temperature)  # softmax\n",
    "    preds = preds / np.sum(preds)                #\n",
    "    probas = np.random.multinomial(1, preds, 1)  # sample index\n",
    "    return np.argmax(probas)                     #\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"Function invoked at end of each epoch. Prints generated text.\"\"\"\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text2) - seqlen - 1)\n",
    "    \n",
    "    for diversity in [0.5]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text2[start_index: start_index + seqlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(1200):\n",
    "            x_pred = np.zeros((1, seqlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "            \n",
    "            preds = model2.predict(x_pred, verbose=0)\n",
    "            next_index = sample(preds[0, -1], diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            \n",
    "            \n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model2.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          callbacks=[print_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8301d53dd684b00c73832b447ead7c53135833981e6900763d37ba09a4e6db7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
